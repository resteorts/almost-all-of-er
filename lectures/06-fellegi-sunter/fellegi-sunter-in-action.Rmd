
---
title: "Module 6: Fellegi-Sunter Method Applied to RLdata500"
author: "Rebecca C. Steorts"
institute: 
output: 
     beamer_presentation:
      includes: 
          in_header: custom2.tex
font-size: 8px
---

## Agenda 

- Let's consider the RLdata500 data set and apply Fellegi Sunter to it
- We will first use the RecordLinkage package 
- Then we will look at a wrapper function that makes this a bit easier. 


## Load packages

```{r, message=FALSE}
library(RecordLinkage)
#library(ffbase)
```

## RLdata500

```{r}
data(RLdata500)
head(RLdata500)
head(identity.RLdata500)
```

## Comparison Vectors

Why do we build record pairs of comparison vectors? 

\textbf{Answer}: Reduce the total number of record comparisons.

## Comparison Vectors

How do we build record pairs of comparison vectors?

\vspace*{1em}

\textbf{Answer}: Use the `compare.dedup` function. 

## Comparison Vectors


```{r}
# create comparison vectors
rpairs <- compare.dedup(RLdata500, 
                        identity = identity.RLdata500)
```

## Comparison Vectors 

\footnotesize
```{r}
# inspect comparison vectors
rpairs$pairs[1:5,]
```

## Blocking

Blocking is the reduction of the amount of data pairs through focusing on specified agreement patterns.

Blocking is a common strategy to reduce computation time and memory consumption by only comparing records with equal values for a subset of attributes, called blocking fields. 

## Blocking

A blocking specification can be supplied to the `compare` function via the argument `blockfld`. 

We will consider a blocking pattern where two records must agree in either the **first component of the first name** or **full date of birth**.

## Blocking and Comparison Vectors

```{r}
# blocking and comparison vectors
rpairs <- compare.dedup(RLdata500, 
                        blockfld = list(1,5:7),
                        identity = identity.RLdata500)
```

## Blocking and Comparison Vectors

\footnotesize
```{r}
# inspect comparison vectors
rpairs$pairs[c(1:3, 1203:1204),]
```


Observe that these records agree on first name but not date of birth (as designed).

## String Comparators

Recall that string comparators measure the similarity between strings, usually with a similarity measure in
the range $[0,1],$ where 0 denotes maximal dissimilarity and 1 equality.

Examples: Edit and Jaro Winkler 

## Blocking and String Comparators

```{r}
# blocking on birth day and month
# use jarowinkler string distance
rpairsfuzzy <- compare.dedup(RLdata500, 
                             blockfld = c(5,6), 
                             strcmp = TRUE,
                             strcmpfun = jarowinkler)

```

Blocking on **birth day and month** where the **Jaro Winkler** string comparator is used.  

## Blocking and String Comparators

\footnotesize
```{r}
# inspect first five record pairs 
rpairsfuzzy$pairs[1:5,]
```


## Probabilistic record linkage

Probabilistic record linkage relies on the assumption of
conditional probabilities concerning comparison patterns.

Recall that we defined the $u$ and $m$ probabilities previously as the following: 



$$u_{\tilde{\gamma}} = P(\gamma = \tilde{\gamma} \mid \text{the records are a match})$$

$$m_{\tilde{\gamma}} = P(\gamma = \tilde{\gamma} \mid \text{the records are not a match}).$$

## Probabilistic record linkage

The probabilities of the random vector $\gamma = (\gamma_1, \ldots \gamma_n)$
having value $\tilde{\gamma} = (\tilde{\gamma}_1, \ldots \tilde{\gamma}_n)$ conditional on the match status $Z$ can more precisely be defined as follows:



$$u_{\tilde{\gamma}} = P(\gamma = \tilde{\gamma} \mid Z=0)$$

$$m_{\tilde{\gamma}} = P(\gamma = \tilde{\gamma} \mid Z=1),$$

where $Z=0$ stands for a non-match and $Z=1$ stands for a match. 

## Probabilistic record linkage

In the Fellegi-Sunter model these probabilities are used to compute weights of the form

$$w_{\tilde{\gamma}} = \log \frac{P(\gamma = \tilde{\gamma} \mid Z=1)}{P(\gamma = \tilde{\gamma} \mid Z=0)}.$$

These weights are used in order to discern between matches and non-matches, where there are several ways to estimate the probabilities/weights.

## EM algorithm


The EM algorithm is used typically to estimate the weights, where the backbone of this algorithm is described by Haber (1984).

Weight calculation based on the EM algorithm and the method by Contiero et al. (2005) are implemented by functions `emWeights` and `epiWeights`.

Calling `summary` on the result shows the distribution of weights in histogram style. 

## EM algorithm

\footnotesize
```{r}
rpairs <- epiWeights(rpairs)
summary(rpairs)
```

## Computing Weight Thresholds

Discernment between matches and non-matches is achieved by means of computing weight thresholds.

The function `epiClassify` allows the user to specify a threshold. 

## Computing Weight Thresholds

\tiny
```{r}
result <- epiClassify(rpairs, 0.55)
#summary(result)
```

## Objects of `result`

We can look at many objects of `result` which include

- data
- pairs
- frequencies
- type 
- Wdatas
- prediction
- threshold

## Evaluation Metrics

\footnotesize

```{r}
fileDir <- "datasets/"
file.name <- "RLdata10000.csv"
filesDf <- read.csv(paste0(fileDir,file.name), na.strings=c("NA"), 
                     stringsAsFactors = FALSE, colClasses = "character")

# ------------------------------- Configuration ------------------------------ #
linkingFields    <- c("fname_c1", "lname_c1", "by", "bm", "bd")
strLinkingFields <- c("fname_c1", "lname_c1")
blockPasses      <- list(c("by"), c("bm", "bd"))
recIdField       <- "rec_id"
entIdField       <- "ent_id"
strDist          <- "levenshtein"
strCutoff        <- 0.70
dataName         <- "RLdata10000"
threshold        <- -10.0
sampleSize       <- c(5, 50) # This give 100 data points
```

## Evaluation Metrics

\footnotesize
```{r, message=FALSE, warning=FALSE}
library(ff)
library(ffbase)
source("fs-code/runFS.R")
runFS(filesDf, linkingFields, strLinkingFields, recIdField, entIdField, blockPasses, 
      strDist, strCutoff, dataName, threshold)
```

## Evaluation Metrics

\footnotesize
```{r, message=FALSE, warning=FALSE}
source("fs-code/evaluationMetrics.R")
source("fs-code/evaluate.R")
evaluate(filesDf, linkingFields, strLinkingFields, recIdField, 
         entIdField, blockPasses, strDist, strCutoff, dataName, 
         threshold, sampleSize)

```
